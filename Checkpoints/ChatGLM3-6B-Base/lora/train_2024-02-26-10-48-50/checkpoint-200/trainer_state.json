{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.371584699453552,
  "eval_steps": 500,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11,
      "grad_norm": 0.4190762937068939,
      "learning_rate": 4.999939076763487e-05,
      "loss": 4.0813,
      "step": 5
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5682299137115479,
      "learning_rate": 4.999756310023261e-05,
      "loss": 3.8759,
      "step": 10
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6293856501579285,
      "learning_rate": 4.999451708687114e-05,
      "loss": 3.9084,
      "step": 15
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8758161664009094,
      "learning_rate": 4.999025287600886e-05,
      "loss": 3.8482,
      "step": 20
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.1061590909957886,
      "learning_rate": 4.99847706754774e-05,
      "loss": 3.9143,
      "step": 25
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0389021635055542,
      "learning_rate": 4.997807075247146e-05,
      "loss": 3.8069,
      "step": 30
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7076208591461182,
      "learning_rate": 4.997015343353585e-05,
      "loss": 3.7051,
      "step": 35
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.0512803792953491,
      "learning_rate": 4.996101910454953e-05,
      "loss": 3.7443,
      "step": 40
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8518654704093933,
      "learning_rate": 4.995066821070679e-05,
      "loss": 3.5774,
      "step": 45
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.9860131144523621,
      "learning_rate": 4.993910125649561e-05,
      "loss": 3.5481,
      "step": 50
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0826561450958252,
      "learning_rate": 4.992631880567301e-05,
      "loss": 3.4416,
      "step": 55
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.8481911420822144,
      "learning_rate": 4.991232148123761e-05,
      "loss": 3.4859,
      "step": 60
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.614713191986084,
      "learning_rate": 4.989710996539926e-05,
      "loss": 3.479,
      "step": 65
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.9479525685310364,
      "learning_rate": 4.988068499954578e-05,
      "loss": 3.3769,
      "step": 70
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.9738621115684509,
      "learning_rate": 4.9863047384206835e-05,
      "loss": 3.3201,
      "step": 75
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.7980673909187317,
      "learning_rate": 4.984419797901491e-05,
      "loss": 3.3725,
      "step": 80
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.7634841203689575,
      "learning_rate": 4.982413770266342e-05,
      "loss": 3.3198,
      "step": 85
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.6109321117401123,
      "learning_rate": 4.980286753286195e-05,
      "loss": 3.3547,
      "step": 90
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.8682252168655396,
      "learning_rate": 4.978038850628854e-05,
      "loss": 3.2288,
      "step": 95
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.9758785963058472,
      "learning_rate": 4.975670171853926e-05,
      "loss": 3.2202,
      "step": 100
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.0699541568756104,
      "learning_rate": 4.9731808324074717e-05,
      "loss": 3.2788,
      "step": 105
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.163353681564331,
      "learning_rate": 4.9705709536163824e-05,
      "loss": 3.2881,
      "step": 110
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.2735884189605713,
      "learning_rate": 4.96784066268247e-05,
      "loss": 3.2715,
      "step": 115
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.9545009732246399,
      "learning_rate": 4.964990092676263e-05,
      "loss": 3.2181,
      "step": 120
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.3793822526931763,
      "learning_rate": 4.962019382530521e-05,
      "loss": 3.1458,
      "step": 125
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.2555819749832153,
      "learning_rate": 4.9589286770334654e-05,
      "loss": 3.247,
      "step": 130
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.3082062005996704,
      "learning_rate": 4.9557181268217227e-05,
      "loss": 3.0994,
      "step": 135
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.440890908241272,
      "learning_rate": 4.952387888372979e-05,
      "loss": 3.065,
      "step": 140
    },
    {
      "epoch": 3.17,
      "grad_norm": 1.061680555343628,
      "learning_rate": 4.94893812399836e-05,
      "loss": 3.1024,
      "step": 145
    },
    {
      "epoch": 3.28,
      "grad_norm": 1.0604188442230225,
      "learning_rate": 4.9453690018345144e-05,
      "loss": 3.1348,
      "step": 150
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.9158951640129089,
      "learning_rate": 4.94168069583542e-05,
      "loss": 3.0929,
      "step": 155
    },
    {
      "epoch": 3.5,
      "grad_norm": 1.9503084421157837,
      "learning_rate": 4.937873385763908e-05,
      "loss": 3.1471,
      "step": 160
    },
    {
      "epoch": 3.61,
      "grad_norm": 1.6482278108596802,
      "learning_rate": 4.933947257182901e-05,
      "loss": 3.1082,
      "step": 165
    },
    {
      "epoch": 3.72,
      "grad_norm": 1.8090347051620483,
      "learning_rate": 4.929902501446366e-05,
      "loss": 3.0517,
      "step": 170
    },
    {
      "epoch": 3.83,
      "grad_norm": 1.215492844581604,
      "learning_rate": 4.925739315689991e-05,
      "loss": 3.0187,
      "step": 175
    },
    {
      "epoch": 3.93,
      "grad_norm": 1.305962085723877,
      "learning_rate": 4.9214579028215776e-05,
      "loss": 3.0567,
      "step": 180
    },
    {
      "epoch": 4.04,
      "grad_norm": 1.4741570949554443,
      "learning_rate": 4.917058471511149e-05,
      "loss": 3.1851,
      "step": 185
    },
    {
      "epoch": 4.15,
      "grad_norm": 1.134225606918335,
      "learning_rate": 4.912541236180779e-05,
      "loss": 3.1119,
      "step": 190
    },
    {
      "epoch": 4.26,
      "grad_norm": 1.534368634223938,
      "learning_rate": 4.907906416994146e-05,
      "loss": 2.9748,
      "step": 195
    },
    {
      "epoch": 4.37,
      "grad_norm": 1.434862732887268,
      "learning_rate": 4.9031542398457974e-05,
      "loss": 3.0311,
      "step": 200
    }
  ],
  "logging_steps": 5,
  "max_steps": 2250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 100,
  "total_flos": 9.226807327555584e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
